1) Purpose (1–2 sentences at top)
* Goal: produce an analysis-ready dataset and document key data quality issues/assumptions.
2) Load Data
* Read dataset
* Quick shape check (# rows/columns)
* Preview sample rows
3) Data Dictionary Snapshot
* List key fields grouped by:
    * Customer demographics
    * Services
    * Billing/account
    * Target label (Churn)
4) Data Quality Audit (show results, not code)
* Missing values by column (counts and %)
* Invalid values / unexpected categories
* Duplicates (customerID uniqueness check)
* Data type issues (especially TotalCharges)
5) Cleaning Decisions (document each)
* Convert TotalCharges to numeric; handle blanks/nulls
* Standardize “Yes/No” fields (consistent casing/spelling)
* Ensure SeniorCitizen is treated correctly (0/1 vs category)
* Drop non-informative identifier (customerID) from modeling/analysis dataset (keep in raw)
6) Feature Engineering (business-focused)
Create a few analyst-friendly features:
* tenure_group (e.g., 0–6, 7–12, 13–24, 25+ months)
* is_high_monthly_charge (top quartile flag)
* avg_charge_per_month = TotalCharges / tenure (handle tenure=0 safely)
* services_count (count of add-ons used)
* Optional: is_auto_pay derived from payment method
7) Output Clean Dataset
* Save to /data/processed/telecom_churn_clean.csv
* Save a small “cleaning summary” table (before vs after)
8) Summary & Assumptions
* 5 bullets:
    * What you cleaned
    * What you created
    * What you excluded
    * Any limitations
